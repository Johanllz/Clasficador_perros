{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# --- Cuaderno para el entrenamiento y fine tuning del clasificador de razas de perros ---\n",
        "# --- Este cuaderno tambien genera un modelo optimizado usando Tensorflow Lite ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYBDcEH4rgir"
      },
      "source": [
        "# --- Bloque 1: Instalación y Carga de Librerías ---\n",
        "# Asegúrate de que el entorno de ejecución (Runtime) en Colab esté configurado para GPU.\n",
        "# Ve a 'Entorno de ejecución' > 'Cambiar tipo de entorno de ejecución' > 'Acelerador de hardware: GPU'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myTgjH_-riYE",
        "outputId": "ea997138-5ccf-4337-bfb5-709ce0f0d9de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.18.0\n",
            "GPU Disponible: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"GPU Disponible: {tf.config.list_physical_devices('GPU')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_v8ledorlMB"
      },
      "source": [
        "\n",
        "# --- Bloque 2: Parámetros y Carga/Preprocesamiento del Dataset ---\n",
        "# Define los parámetros clave y carga el dataset `stanford_dogs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMPAeLfTrl3n",
        "outputId": "8a77d40e-c5df-4a66-9c7b-1487e0b48a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de clases (razas de perros): 120\n",
            "Nombres de las clases (primeras 10): ['n02085620-chihuahua', 'n02085782-japanese_spaniel', 'n02085936-maltese_dog', 'n02086079-pekinese', 'n02086240-shih-tzu', 'n02086646-blenheim_spaniel', 'n02086910-papillon', 'n02087046-toy_terrier', 'n02087394-rhodesian_ridgeback', 'n02088094-afghan_hound']...\n"
          ]
        }
      ],
      "source": [
        "IMG_SIZE = 224 # Tamaño de entrada para MobileNetV2. Las imágenes se redimensionarán a este tamaño.\n",
        "BATCH_SIZE = 32 # Número de imágenes procesadas por lote durante el entrenamiento.\n",
        "SHUFFLE_BUFFER_SIZE = 1000 # Tamaño del buffer para mezclar el dataset, ayuda a la aleatoriedad de los lotes.\n",
        "\n",
        "# Cargar el dataset stanford_dogs\n",
        "# `split=['train', 'test']` divide el dataset en conjuntos de entrenamiento y prueba.\n",
        "# `shuffle_files=True` asegura que los archivos se mezclen antes de cargar.\n",
        "# `with_info=True` devuelve metadatos del dataset, como el número y nombres de las clases.\n",
        "# `as_supervised=True` devuelve el dataset en formato (imagen, etiqueta) directamente.\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'stanford_dogs',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "# Obtener el número total de clases (razas de perros) del dataset.\n",
        "num_classes = ds_info.features['label'].num_classes\n",
        "# Obtener los nombres de las razas. Es crucial guardar esta lista para la aplicación móvil.\n",
        "class_names = ds_info.features['label'].names\n",
        "print(f\"Número de clases (razas de perros): {num_classes}\")\n",
        "print(f\"Nombres de las clases (primeras 10): {class_names[:10]}...\") # Imprime solo las primeras 10 para no saturar\n",
        "\n",
        "# --- Función de Preprocesamiento de Imágenes ---\n",
        "def preprocess_image(image, label):\n",
        "    \"\"\"\n",
        "    Redimensiona la imagen y la normaliza para que los valores de los píxeles estén en el rango [-1, 1].\n",
        "    MobileNetV2 espera entradas en este rango.\n",
        "    \"\"\"\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE)) # Redimensiona la imagen al tamaño requerido por el modelo.\n",
        "    image = tf.cast(image, tf.float32) / 127.5 - 1 # Convierte a float32 y normaliza.\n",
        "    return image, label\n",
        "\n",
        "# Aplicar la función de preprocesamiento a los datasets.\n",
        "# `num_parallel_calls=tf.data.AUTOTUNE` permite que TensorFlow procese las imágenes en paralelo.\n",
        "ds_train = ds_train.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "# Mezclar el dataset de entrenamiento, agrupar en lotes y precargar para optimizar el rendimiento.\n",
        "ds_train = ds_train.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "# Agrupar el dataset de prueba en lotes y precargar.\n",
        "ds_test = ds_test.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6Z4k5u1ryrt"
      },
      "source": [
        "# --- Bloque 3: Construcción del Modelo (Fine-tuning con MobileNetV2) ---\n",
        "# Aquí se define la arquitectura del modelo, utilizando MobileNetV2 como base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "8HsjJ5h-rzW8",
        "outputId": "852b70bf-8c9e-4522-94f8-b4e314a0b57c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Resumen del modelo antes del entrenamiento ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">153,720</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │       \u001b[38;5;34m153,720\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,411,704</span> (9.20 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,411,704\u001b[0m (9.20 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">153,720</span> (600.47 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m153,720\u001b[0m (600.47 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cargar el modelo base pre-entrenado de MobileNetV2 desde Keras Applications.\n",
        "# `input_shape`: Define el tamaño de las imágenes de entrada (224x224 con 3 canales de color).\n",
        "# `include_top=False`: Excluye la capa clasificadora final del modelo original (ImageNet).\n",
        "# `weights='imagenet'`: Usa los pesos pre-entrenados en el gran dataset ImageNet.\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n",
        "# Congelar las capas convolucionales base del modelo.\n",
        "# Esto significa que sus pesos no se actualizarán durante la primera fase del entrenamiento.\n",
        "# Solo entrenaremos las nuevas capas que añadiremos.\n",
        "base_model.trainable = False\n",
        "\n",
        "# --- Construir el nuevo modelo añadiendo capas personalizadas ---\n",
        "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)) # Capa de entrada del modelo.\n",
        "x = base_model(inputs, training=False) # Pasa las entradas a través del modelo base (importante: `training=False` para Batch Normalization).\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x) # Reduce el tensor a un vector promediando los valores espacialmente.\n",
        "x = tf.keras.layers.Dropout(0.2)(x) # Capa de Dropout para regularización, ayuda a prevenir el sobreajuste.\n",
        "outputs = tf.keras.layers.Dense(num_classes)(x) # Capa de salida con el número de clases de razas de perros.\n",
        "                                               # No se aplica Softmax aquí, se maneja en la función de pérdida.\n",
        "\n",
        "# Crear el modelo final combinando las entradas y salidas.\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compilar el modelo.\n",
        "# `optimizer`: Algoritmo de optimización (Adam es una buena opción general).\n",
        "# `loss`: Función de pérdida. SparseCategoricalCrossentropy es adecuada para clasificación multiclase con etiquetas enteras.\n",
        "#         `from_logits=True` indica que la capa de salida no tiene una activación Softmax.\n",
        "# `metrics`: Métrica para monitorear durante el entrenamiento (precisión).\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n--- Resumen del modelo antes del entrenamiento ---\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spcf_GMjr2VT"
      },
      "source": [
        "# --- Bloque 4: Entrenamiento del Modelo (Fase 1: Capas Nuevas Congeladas) ---\n",
        "# En esta fase, solo se entrenan las capas que añadimos (Pooling, Dropout, Dense)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3AJJHSCr4jk",
        "outputId": "a9c11dd3-f30c-4b95-d7d1-432727d22b72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Iniciando entrenamiento (Fase 1) por 10 épocas ---\n",
            "Epoch 1/10\n"
          ]
        }
      ],
      "source": [
        "initial_epochs = 10 # Número de épocas para la primera fase de entrenamiento. Puedes ajustar este valor.\n",
        "\n",
        "print(f\"\\n--- Iniciando entrenamiento (Fase 1) por {initial_epochs} épocas ---\")\n",
        "history = model.fit(ds_train,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=ds_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFKKeudyr86m"
      },
      "source": [
        "# --- Bloque 5: Descongelar y Entrenar (Fase 2: Fine-tuning) ---\n",
        "# Aquí se permite que algunas capas del modelo base también se entrenen, afinando el modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6Z669lor_Fb"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True # Hacer todas las capas del modelo base entrenables.\n",
        "\n",
        "# Iterar sobre las capas del modelo base y congelar las que no queremos afinar.\n",
        "# Un valor común es descongelar la última parte del modelo base, por ejemplo, las últimas 50-100 capas.\n",
        "# Ajusta `fine_tune_at` para controlar cuántas capas se entrenan del modelo base.\n",
        "fine_tune_at = 100\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompilar el modelo después de cambiar la entrenabilidad de las capas.\n",
        "# Es fundamental recompilar para que los cambios en `trainable` surtan efecto.\n",
        "# Usamos un learning rate mucho más bajo para el fine-tuning para evitar corromper los pesos pre-entrenados.\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n--- Resumen del modelo después de descongelar capas para fine-tuning ---\")\n",
        "model.summary()\n",
        "\n",
        "# --- Entrenamiento del modelo (Fase 2: Fine-tuning) ---\n",
        "fine_tune_epochs = 10 # Número de épocas para la fase de fine-tuning.\n",
        "total_epochs = initial_epochs + fine_tune_epochs # Épocas totales combinadas.\n",
        "\n",
        "print(f\"\\n--- Iniciando fine-tuning (Fase 2) por {fine_tune_epochs} épocas adicionales ---\")\n",
        "history_fine_tune = model.fit(ds_train,\n",
        "                              epochs=total_epochs,\n",
        "                              initial_epoch=history.epoch[-1], # Continúa el entrenamiento desde la última época de la Fase 1.\n",
        "                              validation_data=ds_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_T9uns0sBGV"
      },
      "source": [
        "# --- Bloque 6: Evaluación del Modelo y Visualización ---\n",
        "# Combina los datos de historial de ambas fases para una visualización completa del progreso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLT4ocYysC13"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy'] + history_fine_tune.history['accuracy']\n",
        "val_acc = history.history['val_accuracy'] + history_fine_tune.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss'] + history_fine_tune.history['loss']\n",
        "val_loss = history.history['val_loss'] + history_fine_tune.history['val_loss']\n",
        "\n",
        "# Graficar la precisión de entrenamiento y validación\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Precisión de Entrenamiento')\n",
        "plt.plot(val_acc, label='Precisión de Validación')\n",
        "plt.ylim([0.0, 1])\n",
        "# Línea vertical para marcar el inicio del fine-tuning\n",
        "plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "          plt.ylim(), label='Inicio Fine-tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Precisión de Entrenamiento y Validación')\n",
        "\n",
        "# Graficar la pérdida de entrenamiento y validación\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Pérdida de Entrenamiento')\n",
        "plt.plot(val_loss, label='Pérdida de Validación')\n",
        "plt.ylim([0, 1.0])\n",
        "# Línea vertical para marcar el inicio del fine-tuning\n",
        "plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "         plt.ylim(), label='Inicio Fine-tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Pérdida de Entrenamiento y Validación')\n",
        "plt.xlabel('Época')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Evaluación final del modelo en el set de prueba\n",
        "loss, accuracy = model.evaluate(ds_test)\n",
        "print(f\"\\nPrecisión final en el set de prueba: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMz1t4dnsE3X"
      },
      "source": [
        "# --- Bloque 7: Conversión a TensorFlow Lite y Descarga ---\n",
        "# Este bloque convierte el modelo entrenado a un archivo `.tflite` y guarda las etiquetas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvFAAhEksF5L"
      },
      "outputs": [],
      "source": [
        "# Para TFLite, generalmente queremos que el modelo de salida dé probabilidades (softmax).\n",
        "# Durante el entrenamiento, usamos `from_logits=True` en la función de pérdida para mayor estabilidad numérica.\n",
        "# Aquí, creamos un modelo temporal que incluye una capa Softmax al final.\n",
        "model_for_tflite = tf.keras.Sequential([\n",
        "    model, # Tu modelo entrenado\n",
        "    tf.keras.layers.Softmax() # Añade la capa Softmax para obtener probabilidades\n",
        "])\n",
        "\n",
        "# Crear el convertidor de TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_tflite)\n",
        "\n",
        "# Optimización (opcional pero muy recomendable para dispositivos móviles)\n",
        "# `tf.lite.Optimize.DEFAULT` aplica optimizaciones como la cuantificación de pesos (a 8 bits por defecto),\n",
        "# lo que reduce el tamaño del modelo y acelera la inferencia.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_model = converter.convert() # Realiza la conversión.\n",
        "\n",
        "# Guardar el modelo .tflite en un directorio.\n",
        "tflite_models_dir = 'tflite_models'\n",
        "os.makedirs(tflite_models_dir, exist_ok=True) # Crea el directorio si no existe.\n",
        "tflite_model_path = os.path.join(tflite_models_dir, 'stanford_dogs_classifier.tflite')\n",
        "\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(f\"\\nModelo TFLite guardado en: {tflite_model_path}\")\n",
        "\n",
        "# --- Guardar los Nombres de las Clases ---\n",
        "# Es CRUCIAL que este archivo de etiquetas se incluya en tu aplicación móvil\n",
        "# y se lea en el mismo orden para mapear las predicciones numéricas a los nombres de las razas.\n",
        "labels_path = os.path.join(tflite_models_dir, 'labels.txt')\n",
        "with open(labels_path, 'w') as f:\n",
        "    for name in class_names:\n",
        "        f.write(f\"{name}\\n\")\n",
        "\n",
        "print(f\"Archivo de etiquetas guardado en: {labels_path}\")\n",
        "\n",
        "# --- Descargar los Archivos ---\n",
        "# Esta celda te permitirá descargar el modelo .tflite y el archivo de etiquetas directamente desde Colab.\n",
        "from google.colab import files\n",
        "print(\"\\nPreparando la descarga de los archivos...\")\n",
        "files.download(tflite_model_path)\n",
        "files.download(labels_path)\n",
        "print(\"¡Descarga completada! Revisa las descargas de tu navegador.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
